# Use some data
library(ggplot2)
MyData<- read.csv("Total-occurrencce.csv", sep=",")
mat <- MyData[,c(1,3,16,2,24,4,38,9,12,30,15)]

# Index combinations of columns
# Not very efficient, but it'll do for now
idx <- expand.grid(colnames(mat), colnames(mat))

# Loop over indices, calculate p-value
pvals <- apply(idx, 1, function(i){
  x <- mat[,i[[1]]]
  y <- mat[,i[[2]]]
  cor.test(x, y, method = "kendall")$p.value
})
# Combine indices with pvalues, do some sort of multiple testing correction
# Note that we are testing column combinations twice 
# so we're overcorrecting with the FDR here
pvals <- cbind.data.frame(idx, pvals = p.adjust(pvals, "fdr"))

# Calculate basic correlation
cors <- cor(mat, method = "kendall")
cors <- reshape2::melt(cors)

# Indices of correlations and pvalues should be the same, thus can be merged
if (identical(cors[,1:2], pvals[,1:2])) {
  df <- cbind.data.frame(pvals, cor = cors[,3])
}

# Plot a matrix
ggplot(df, aes(Var1, Var2, fill = ifelse(pvals < 0.05, cor, 0))) +
  geom_raster()+labs(x="Actions", y="Actions")+geom_text(aes(label=sprintf("%0.2f",round(cor,digits=2))))+theme(axis.text.x = element_text(angle = 45,size = 11,vjust = 1,hjust = 1))+
  scale_fill_gradient2(name = "Significant Correlation", limits = c(-1, 1))
